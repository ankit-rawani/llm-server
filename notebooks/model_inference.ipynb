{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quantized LLM Inferencing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from threading import Thread\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, GenerationConfig, TextIteratorStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    tokenizer.pad_token = tokenizer.unk_token\n",
    "    tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "    tokenizer.padding_side = \"left\"\n",
    "\n",
    "    streamer = TextIteratorStreamer(tokenizer)\n",
    "\n",
    "    compute_dtype = getattr(torch, \"bfloat16\")\n",
    "    \n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\": 0},\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        cache_dir=f\"../models\",\n",
    "        local_files_only=True\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer, streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759e1a7ae4b047cf8f6816e2285cfabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model, tokenizer, streamer = get_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction):\n",
    "    prompt = \"[INST]\" + instruction + \"[/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=GenerationConfig(pad_token_id=tokenizer.pad_token_id, temperature=1.0, top_p=1.0, top_k=50, num_beams=1),\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "\n",
    "    for seq in generation_output.sequences:\n",
    "        output = tokenizer.decode(seq)\n",
    "        response += output.split(\"[/INST]\")[1].strip()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stream(instruction):\n",
    "    prompt = \"[INST]\" + instruction + \"[/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    generation_kwargs = dict(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=GenerationConfig(pad_token_id=tokenizer.pad_token_id, temperature=1.0, top_p=1.0, top_k=50, num_beams=1),\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256,\n",
    "        streamer=streamer\n",
    "    )\n",
    "\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "\n",
    "    for new_text in streamer:\n",
    "        yield new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Tell me about gravitation.\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]Tell me about \n",
      "gravitation.[/INST] \n",
      "\n",
      "\n",
      "Gravitation \n",
      "is \n",
      "a \n",
      "fundamental \n",
      "force \n",
      "of \n",
      "nature \n",
      "that \n",
      "\n",
      "attracts \n",
      "two \n",
      "bodies \n",
      "towards \n",
      "each \n",
      "\n",
      "other. \n",
      "It \n",
      "is \n",
      "a \n",
      "force \n",
      "that \n",
      "exists \n",
      "between \n",
      "any \n",
      "two \n",
      "objects \n",
      "with \n",
      "\n",
      "mass, \n",
      "and \n",
      "the \n",
      "strength \n",
      "of \n",
      "the \n",
      "force \n",
      "is \n",
      "directly \n",
      "\n",
      "proportional \n",
      "to \n",
      "the \n",
      "product \n",
      "of \n",
      "their \n",
      "masses \n",
      "and \n",
      "\n",
      "\n",
      "inversely \n",
      "\n",
      "proportional \n",
      "to \n",
      "the \n",
      "square \n",
      "of \n",
      "the \n",
      "distance \n",
      "between \n",
      "\n",
      "them.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The \n",
      "force \n",
      "of \n",
      "gravity \n",
      "is \n",
      "what \n",
      "keeps \n",
      "planets \n",
      "in \n",
      "orbit \n",
      "around \n",
      "the \n",
      "\n",
      "sun, \n",
      "and \n",
      "it \n",
      "is \n",
      "also \n",
      "what \n",
      "causes \n",
      "objects \n",
      "to \n",
      "fall \n",
      "towards \n",
      "the \n",
      "ground \n",
      "when \n",
      "\n",
      "dropped. \n",
      "\n",
      "Gravity \n",
      "is \n",
      "a \n",
      "force \n",
      "that \n",
      "acts \n",
      "over \n",
      "very \n",
      "large \n",
      "\n",
      "distances, \n",
      "and \n",
      "its \n",
      "effects \n",
      "can \n",
      "be \n",
      "observed \n",
      "on \n",
      "a \n",
      "\n",
      "cosmic \n",
      "\n",
      "scale, \n",
      "as \n",
      "well \n",
      "as \n",
      "on \n",
      "a \n",
      "very \n",
      "small \n",
      "\n",
      "scale.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Gravity \n",
      "is \n",
      "described \n",
      "by \n",
      "Isaac \n",
      "\n",
      "\n",
      "Newton's \n",
      "law \n",
      "of \n",
      "universal \n",
      "\n",
      "\n",
      "gravitation, \n",
      "which \n",
      "states \n",
      "that \n",
      "every \n",
      "point \n",
      "mass \n",
      "\n",
      "attracts \n",
      "every \n",
      "other \n",
      "point \n",
      "mass \n",
      "by \n",
      "a \n",
      "force \n",
      "acting \n",
      "along \n",
      "the \n",
      "line \n",
      "\n",
      "\n",
      "intersecting \n",
      "both \n",
      "\n",
      "points. \n",
      "The \n",
      "force \n",
      "is \n",
      "equal \n",
      "to \n",
      "the \n",
      "product \n",
      "of \n",
      "the \n",
      "two \n",
      "masses \n",
      "and \n",
      "\n",
      "\n",
      "inversely \n",
      "\n",
      "proportional \n",
      "to \n",
      "the \n",
      "square \n",
      "of \n",
      "the \n",
      "distance \n",
      "between \n",
      "their \n",
      "\n",
      "centers.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In \n",
      "\n",
      "\n",
      "Einstein's \n",
      "theory \n",
      "of \n",
      "general \n",
      "\n",
      "\n",
      "relativity, \n",
      "gravity \n",
      "is \n",
      "explained \n",
      "as \n",
      "the \n",
      "\n",
      "curvature \n",
      "of \n",
      "space \n",
      "and \n",
      "time \n",
      "caused \n",
      "by \n",
      "the \n",
      "presence \n",
      "of \n",
      "mass \n",
      "and \n",
      "\n",
      "energy. \n",
      "According \n",
      "to \n",
      "this \n",
      "\n",
      "theory, \n",
      "massive \n",
      "objects \n",
      "like \n",
      "planets \n",
      "and \n",
      "stars \n",
      "bend \n",
      "space \n",
      "and \n",
      "time \n",
      "around \n",
      "\n",
      "them, \n",
      "causing \n",
      "other \n",
      "objects \n",
      "to \n",
      "move \n",
      "along \n",
      "\n",
      "curved \n",
      "paths \n",
      "and \n",
      "experience\n"
     ]
    }
   ],
   "source": [
    "iter = generate_stream(\"Tell me about gravitation.\")\n",
    "\n",
    "for i in iter:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
